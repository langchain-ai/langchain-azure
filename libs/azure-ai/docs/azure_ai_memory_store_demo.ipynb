{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Azure AI Memory Store with LangGraph\n",
    "\n",
    "This notebook demonstrates how to use `AzureAIMemoryStore` to persist and retrieve\n",
    "agent memories using the Azure AI Projects SDK V2 and LangGraph's `BaseStore` interface.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. A Microsoft Foundry project.\n",
    "2. A deployed chat model (e.g., `gpt-4.1`).\n",
    "3. A deployed embedding model (e.g., `text-embedding-3-small`).\n",
    "4. An existing Azure AI memory store in your project.\n",
    "5. Environment variables set:\n",
    "\n",
    "   - `AZURE_AI_PROJECT_ENDPOINT`\n",
    "   - `MEMORY_STORE_NAME`\n",
    "\n",
    "6. Install dependencies:\n",
    "\n",
    "   ```\n",
    "   pip install 'azure-ai-projects>=2.0.0b1' --pre\n",
    "   pip install langchain-azure-ai langgraph\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"AZURE_AI_PROJECT_ENDPOINT\"] = (\n",
    "    \"https://<resource>.services.ai.azure.com/api/projects/<project>\"\n",
    ")\n",
    "os.environ[\"MEMORY_STORE_NAME\"] = \"my-memory-store\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6",
   "metadata": {},
   "source": [
    "## Create a memory store in Azure AI Projects\n",
    "\n",
    "The memory store must exist before we can use `AzureAIMemoryStore`.\n",
    "The code below creates one if it does not already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import (\n",
    "    MemoryStoreDefaultDefinition,\n",
    "    MemoryStoreDefaultOptions,\n",
    ")\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "endpoint = os.environ[\"AZURE_AI_PROJECT_ENDPOINT\"]\n",
    "memory_store_name = os.environ[\"MEMORY_STORE_NAME\"]\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "try:\n",
    "    definition = MemoryStoreDefaultDefinition(\n",
    "        chat_model=\"gpt-4.1\",\n",
    "        embedding_model=\"text-embedding-3-small\",\n",
    "        options=MemoryStoreDefaultOptions(\n",
    "            user_profile_enabled=True,\n",
    "            chat_summary_enabled=True,\n",
    "        ),\n",
    "    )\n",
    "    memory_store = project_client.beta.memory_stores.create(\n",
    "        name=memory_store_name,\n",
    "        description=\"LangGraph memory store demo\",\n",
    "        definition=definition,\n",
    "    )\n",
    "    print(f\"Created memory store: {memory_store.name}\")\n",
    "except ResourceExistsError:\n",
    "    print(f\"Memory store '{memory_store_name}' already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8",
   "metadata": {},
   "source": [
    "## Initialise AzureAIMemoryStore\n",
    "\n",
    "`AzureAIMemoryStore` wraps the Azure AI memory store and implements the LangGraph\n",
    "`BaseStore` interface so it can be passed directly to any LangGraph graph or agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_azure_ai.stores import AzureAIMemoryStore\n",
    "\n",
    "store = AzureAIMemoryStore(\n",
    "    project_client=project_client,\n",
    "    memory_store_name=memory_store_name,\n",
    ")\n",
    "\n",
    "print(\"AzureAIMemoryStore ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0",
   "metadata": {},
   "source": [
    "## Put – store memories\n",
    "\n",
    "Use `store.put(namespace, key, value)` to persist a memory.  \n",
    "The namespace is a tuple of strings that groups related memories (e.g. by user ID).  \n",
    "The value is any JSON-serialisable dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a user preference\n",
    "store.put(\n",
    "    (\"users\", \"alice\"),\n",
    "    \"preferences\",\n",
    "    {\"theme\": \"dark\", \"language\": \"en\", \"coffee\": \"dark roast\"},\n",
    ")\n",
    "\n",
    "# Store a fact about the user\n",
    "store.put(\n",
    "    (\"users\", \"alice\"),\n",
    "    \"profile\",\n",
    "    {\"name\": \"Alice\", \"location\": \"Seattle\", \"role\": \"engineer\"},\n",
    ")\n",
    "\n",
    "print(\"Memories stored\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "## Get – retrieve a specific memory by key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = store.get((\"users\", \"alice\"), \"preferences\")\n",
    "if item:\n",
    "    print(f\"Found: key={item.key}, value={item.value}\")\n",
    "else:\n",
    "    print(\"Not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "## Search – semantic search over memories\n",
    "\n",
    "Use `store.search(namespace_prefix, query=...)` to find memories semantically\n",
    "relevant to a natural-language query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = store.search((\"users\", \"alice\"), query=\"What coffee does Alice prefer?\")\n",
    "for result in results:\n",
    "    print(f\"key={result.key}, value={result.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6",
   "metadata": {},
   "source": [
    "## Delete – remove memories for a namespace\n",
    "\n",
    "Passing `value=None` to `put()` deletes all memories for the given namespace scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "store.delete((\"users\", \"alice\"), \"preferences\")\n",
    "print(\"Deleted preferences namespace scope\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6e7f8",
   "metadata": {},
   "source": [
    "## Use with a LangGraph agent\n",
    "\n",
    "Pass the store directly to any LangGraph graph as the `store` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, MessagesState, StateGraph\n",
    "\n",
    "\n",
    "def agent_node(state: MessagesState, store: AzureAIMemoryStore) -> dict:  # type: ignore[type-arg]\n",
    "    \"\"\"Simple agent that retrieves memories and returns a greeting.\"\"\"\n",
    "    user_id = \"alice\"\n",
    "    memories = store.search(\n",
    "        (\"users\", user_id),\n",
    "        query=state[\"messages\"][-1].content,\n",
    "    )\n",
    "    memory_context = \"\\n\".join(\n",
    "        f\"- {m.key}: {m.value}\" for m in memories\n",
    "    )\n",
    "    from langchain_core.messages import AIMessage\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            AIMessage(\n",
    "                content=f\"I found the following memories:\\n{memory_context}\"\n",
    "            )\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"agent\", agent_node)\n",
    "builder.add_edge(START, \"agent\")\n",
    "builder.add_edge(\"agent\", END)\n",
    "\n",
    "graph = builder.compile(store=store, checkpointer=MemorySaver())\n",
    "\n",
    "response = graph.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"What are Alice's coffee preferences?\")]},\n",
    "    config={\"configurable\": {\"thread_id\": \"thread-1\"}},\n",
    ")\n",
    "\n",
    "for msg in response[\"messages\"]:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8a9b0",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_client.beta.memory_stores.delete(memory_store_name)\n",
    "print(f\"Memory store '{memory_store_name}' deleted\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-azure-ai-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
